{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = 'pictest/aa2.jpeg'\n",
    "img2_path = 'pictest/aa3.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-08-12 20:26:27 - Found 7 newly added image(s), 0 removed image(s), 0 replaced image(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 7/7 [00:02<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-08-12 20:26:29 - There are now 8 representations in ds_model_vggface_detector_opencv_aligned_normalization_base_expand_0.pkl\n",
      "24-08-12 20:26:29 - Searching pictest/source.jpeg in 8 length datastore\n",
      "24-08-12 20:26:29 - find function duration 2.779038906097412 seconds\n"
     ]
    }
   ],
   "source": [
    "df = DeepFace.find(img_path='pictest/source.jpeg', db_path='pictest/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[              identity                                      hash  target_x  \\\n",
       " 0     pictest/aa1.jpeg  d097f97ce6ce55b1dce233567fe7cc130be0bad3       226   \n",
       " 1  pictest/source.jpeg  085545a9ed9c3b58a4d35639d253d415ae9fac54       226   \n",
       " 2     pictest/aa5.jpeg  a50534f52eab88dd272ab664ee5d1c1f4d4a1f7a       463   \n",
       " 3    pictest/nex1.jpeg  0e85cc928080b5a1e8d5a830e775780de4ae5580       282   \n",
       " 4     pictest/aa2.jpeg  e61d5a6ebcb27e66c8c1b4475ceb2b2b958c8801       173   \n",
       " \n",
       "    target_y  target_w  target_h  source_x  source_y  source_w  source_h  \\\n",
       " 0       143       267       267       226       143       267       267   \n",
       " 1       143       267       267       226       143       267       267   \n",
       " 2       231        53        53       226       143       267       267   \n",
       " 3       676       187       187       226       143       267       267   \n",
       " 4       184       252       252       226       143       267       267   \n",
       " \n",
       "    threshold  distance  \n",
       " 0       0.68  0.000000  \n",
       " 1       0.68  0.000000  \n",
       " 2       0.68  0.468612  \n",
       " 3       0.68  0.509848  \n",
       " 4       0.68  0.516092  ]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]  \n"
     ]
    }
   ],
   "source": [
    "obj = DeepFace.analyze(img_path = img1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'emotion': {'angry': 0.0028335569238151824,\n",
       "   'disgust': 2.34501504184917e-17,\n",
       "   'fear': 1.5086830561568174,\n",
       "   'happy': 98.47170105407841,\n",
       "   'sad': 1.1711284018939032e-05,\n",
       "   'surprise': 0.016659806253134832,\n",
       "   'neutral': 0.0001109446837025378},\n",
       "  'dominant_emotion': 'happy',\n",
       "  'region': {'x': 173,\n",
       "   'y': 184,\n",
       "   'w': 252,\n",
       "   'h': 252,\n",
       "   'left_eye': (357, 383),\n",
       "   'right_eye': (254, 275)},\n",
       "  'face_confidence': 0.94,\n",
       "  'age': 39,\n",
       "  'gender': {'Woman': 8.086401969194412, 'Man': 91.91359281539917},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': 13.48259449005127,\n",
       "   'indian': 6.969121098518372,\n",
       "   'black': 1.960870809853077,\n",
       "   'white': 34.34876203536987,\n",
       "   'middle eastern': 20.87647318840027,\n",
       "   'latino hispanic': 22.362181544303894},\n",
       "  'dominant_race': 'white'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
